# ğŸ–ï¸ GesturAI: Real-Time Hand Gesture Control System

A real-time hand gesture recognition system using MediaPipe and PyTorch to control system commands like opening a terminal, copying text, or pausing videos.

---

## ğŸ”§ Features

- âœ… Real-time gesture recognition using webcam  
- âœ… Context-aware gesture modes (`media_mode`, `word_mode`, `presentation_mode`)  
- âœ… Customizable gesture-to-action mappings  
- âœ… Streamlit UI for editing gesture mappings  
- âœ… Cross-platform (macOS, Linux, Windows)  

---

## ğŸ“‚ Project Structure

```
GesturAI/
â”‚
â”œâ”€â”€ actions.py              # Maps gestures to system commands
â”œâ”€â”€ collect_data.py         # Collects gesture data via webcam
â”œâ”€â”€ gesture_data.pkl        # (ignored) Collected training data
â”œâ”€â”€ gesture_model.pth       # (ignored) Trained PyTorch model
â”œâ”€â”€ label_map.pkl           # (ignored) Label-to-gesture mapping
â”œâ”€â”€ model.py                # PyTorch MLP model definition
â”œâ”€â”€ run_gesture_control.py  # Main real-time gesture prediction script
â”œâ”€â”€ training.py             # Trains the classifier
â”œâ”€â”€ hand_tracker.py         # MediaPipe-based hand landmark tracking
â”œâ”€â”€ gesture_ui_mapper.py    # Streamlit app for updating gesture mappings
â”œâ”€â”€ gesture_cli_mapper.py   # CLI to update gesture-action mapping
â”œâ”€â”€ gesture_config.json     # Saved gesture-action mappings
â”œâ”€â”€ requirements.txt        # All dependencies
â””â”€â”€ README.md               # Project overview
```

---

## ğŸš€ Getting Started

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Collect Gesture Data

```bash
python collect_data.py
```

### 3. Train the Model

```bash
python training.py
```

### 4. Map Gestures to Actions

```bash
# Option A: Streamlit UI
streamlit run gesture_ui_mapper.py

# Option B: CLI
python gesture_cli_mapper.py
```

### 5. Run Gesture Controller

```bash
python run_gesture_control.py
```

---

## âœ‹ Example Gestures & Actions

| Gesture         | Action               | Context           |
|------------------|------------------------|--------------------|
| `fist`           | Open Terminal          | default            |
| `thumbs_up`      | Open Browser           | default            |
| `peace_sign`     | Copy                   | word_mode          |
| `palm`           | Paste                  | word_mode          |
| `pinch`          | Pause YouTube          | media_mode         |
| `swipe_right`    | Next Slide             | presentation_mode  |
| `swipe_left`     | Previous Slide         | presentation_mode  |

---

## ğŸ§  Context Modes

- `default`
- `word_mode`
- `media_mode`
- `presentation_mode`

You can switch between modes using trigger gestures like `three_fingers`, `peace_sign`, or `ok_sign`.

---

## ğŸ” Customize Your Mappings

Use `gesture_ui_mapper.py` to:

- Add new gestures  
- Map gestures to system actions  
- Delete or reset mappings  
- Save to `gesture_config.json`  

---

## ğŸ“Œ Future Ideas

- Record your own custom gestures  
- Add voice feedback or sound effects  
- Integrate with specific apps (Zoom, PowerPoint, etc.)  
- Cloud-hosted UI for remote gesture mapping  

